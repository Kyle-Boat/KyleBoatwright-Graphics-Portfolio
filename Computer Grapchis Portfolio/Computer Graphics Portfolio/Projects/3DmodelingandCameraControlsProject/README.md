This project focuses on 3D modeling, importing assets, and implementing interactive camera controls in openFrameworks. It begins with creating a simple scene in Blender composed of primitive objects positioned through translation, rotation, and scaling. Once exported in the .ply format, these models are loaded into openFrameworks as meshes and rendered together on screen. Each model is assigned its own transformation so they don’t overlap, and the scene is displayed with a perspective projection. A fragment shader is also written to visualize normals, transforming them into world space using a normal matrix.

After the models are loaded and rendered, the project extends into building a camera system. First-person “flying camera” controls are added, supporting six-directional movement—forward, backward, left, right, up, and down—relative to the camera’s orientation. Mouse input controls head and pitch rotation, allowing users to freely navigate the 3D environment.

Once the camera is implemented, the project shifts toward performance testing and optimization. The scene is stress tested by drawing thousands of model instances, then optimized by switching from direct mesh drawing to vertex buffer objects (VBOs). This change significantly improves rendering performance, highlighting the efficiency of GPU-accelerated rendering.


Finally, a fog effect is added using alpha blending. By calculating the camera-space position of fragments in the shader and adjusting alpha values based on distance, objects fade smoothly into the background as they approach the far plane. The implementation uses GLSL functions such as smoothstep() for a natural transition, and back-face culling is enabled to avoid artifacts. Together, these steps result in an interactive, optimized 3D scene with camera navigation, shading, and atmospheric effects.